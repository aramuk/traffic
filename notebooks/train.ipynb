{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import _fix_paths\n",
    "from lib.data import PEMSBay\n",
    "from lib.models import STGCN_VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIST_WINDOW = 12\n",
    "PRED_WINDOW = 12\n",
    "LATENT_DIM = 325\n",
    "LEARNING_RATE = 0.01\n",
    "WEIGHT_DECAY = 5e-4\n",
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 8\n",
    "TEMPORAL_KERNEL = 3\n",
    "SPATIAL_KERNEL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/pytables.py:3007: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  index = factory(\n"
     ]
    }
   ],
   "source": [
    "train_set = PEMSBay('../datasets/PEMS-BAY', 'train', HIST_WINDOW, PRED_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = STGCN_VAE(\n",
    "    SPATIAL_KERNEL, TEMPORAL_KERNEL, [(HIST_WINDOW + PRED_WINDOW, 16, 64), (64, 32, 128)], LATENT_DIM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STGCN_VAE(\n",
      "  (encoder): ModuleList(\n",
      "    (0): SpatioTemporalConv(\n",
      "      (temporal_conv1): TemporalConv(\n",
      "        (align): Align(\n",
      "          (conv): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n",
      "        )\n",
      "        (gconv): ChebConv(24, 16, K=3, normalization=sym)\n",
      "      )\n",
      "      (spatial_conv): SpatialConv(\n",
      "        (align): Align(\n",
      "          (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n",
      "        )\n",
      "        (gconv): ChebConv(16, 16, K=3, normalization=sym)\n",
      "      )\n",
      "      (temporal_conv2): TemporalConv(\n",
      "        (align): Align(\n",
      "          (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n",
      "        )\n",
      "        (gconv): ChebConv(16, 64, K=3, normalization=sym)\n",
      "      )\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): SpatioTemporalConv(\n",
      "      (temporal_conv1): TemporalConv(\n",
      "        (align): Align(\n",
      "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n",
      "        )\n",
      "        (gconv): ChebConv(64, 32, K=3, normalization=sym)\n",
      "      )\n",
      "      (spatial_conv): SpatialConv(\n",
      "        (align): Align(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n",
      "        )\n",
      "        (gconv): ChebConv(32, 32, K=3, normalization=sym)\n",
      "      )\n",
      "      (temporal_conv2): TemporalConv(\n",
      "        (align): Align(\n",
      "          (conv): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n",
      "        )\n",
      "        (gconv): ChebConv(32, 128, K=3, normalization=sym)\n",
      "      )\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (conv_mu): GCNConv(128, 1)\n",
      "  (conv_var): GCNConv(128, 1)\n",
      "  (decoder): ModuleList(\n",
      "    (0): ResidualGConv(\n",
      "      (gconv): GCNConv(1, 16)\n",
      "      (align): Align(\n",
      "        (conv): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualGConv(\n",
      "      (gconv): GCNConv(16, 32)\n",
      "      (align): Align(\n",
      "        (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualGConv(\n",
      "      (gconv): GCNConv(32, 1)\n",
      "      (align): Align(\n",
      "        (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "edge_idx = train_set.edge_idx.to(device)\n",
    "edge_wt = train_set.edge_wt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "loss_mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 325, 12]), torch.Size([8, 1, 325, 12]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2a82b95cc84cf882bbe6e082527915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([8, 1, 325, 1])) that is different to the input size (torch.Size([8, 1, 325, 12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/201]: loss = 4519.2393\n",
      "[Epoch 2/201]: loss = 4328.8296\n",
      "[Epoch 3/201]: loss = 3966.7544\n",
      "[Epoch 4/201]: loss = 2659.7573\n",
      "[Epoch 5/201]: loss = 439.5177\n",
      "[Epoch 6/201]: loss = 3649.3193\n",
      "[Epoch 7/201]: loss = 846.6057\n",
      "[Epoch 8/201]: loss = 1864.3613\n",
      "[Epoch 9/201]: loss = 2198.8323\n",
      "[Epoch 10/201]: loss = 2229.4685\n",
      "[Epoch 11/201]: loss = 2057.2114\n",
      "[Epoch 12/201]: loss = 1670.2412\n",
      "[Epoch 13/201]: loss = 1129.2440\n",
      "[Epoch 14/201]: loss = 674.4900\n",
      "[Epoch 15/201]: loss = 347.0389\n",
      "[Epoch 16/201]: loss = 402.9964\n",
      "[Epoch 17/201]: loss = 398.0255\n",
      "[Epoch 18/201]: loss = 298.7583\n",
      "[Epoch 19/201]: loss = 375.0571\n",
      "[Epoch 20/201]: loss = 305.1799\n",
      "[Epoch 21/201]: loss = 315.4176\n",
      "[Epoch 22/201]: loss = 295.1932\n",
      "[Epoch 23/201]: loss = 265.1424\n",
      "[Epoch 24/201]: loss = 268.0796\n",
      "[Epoch 25/201]: loss = 270.4122\n",
      "[Epoch 26/201]: loss = 253.3183\n",
      "[Epoch 27/201]: loss = 282.4642\n",
      "[Epoch 28/201]: loss = 247.5415\n",
      "[Epoch 29/201]: loss = 252.8288\n",
      "[Epoch 30/201]: loss = 268.6562\n",
      "[Epoch 31/201]: loss = 232.6919\n",
      "[Epoch 32/201]: loss = 238.4065\n",
      "[Epoch 33/201]: loss = 224.7401\n",
      "[Epoch 34/201]: loss = 236.2421\n",
      "[Epoch 35/201]: loss = 218.3169\n",
      "[Epoch 36/201]: loss = 209.6213\n",
      "[Epoch 37/201]: loss = 193.4093\n",
      "[Epoch 38/201]: loss = 210.4103\n",
      "[Epoch 39/201]: loss = 197.0160\n",
      "[Epoch 40/201]: loss = 207.7155\n",
      "[Epoch 41/201]: loss = 207.9079\n",
      "[Epoch 42/201]: loss = 182.6342\n",
      "[Epoch 43/201]: loss = 186.9275\n",
      "[Epoch 44/201]: loss = 205.7854\n",
      "[Epoch 45/201]: loss = 182.0748\n",
      "[Epoch 46/201]: loss = 169.1444\n",
      "[Epoch 47/201]: loss = 182.6425\n",
      "[Epoch 48/201]: loss = 157.7480\n",
      "[Epoch 49/201]: loss = 172.0913\n",
      "[Epoch 50/201]: loss = 149.2198\n",
      "[Epoch 51/201]: loss = 166.7975\n",
      "[Epoch 52/201]: loss = 155.3976\n",
      "[Epoch 53/201]: loss = 142.9749\n",
      "[Epoch 54/201]: loss = 144.1440\n",
      "[Epoch 55/201]: loss = 141.8938\n",
      "[Epoch 56/201]: loss = 129.9617\n",
      "[Epoch 57/201]: loss = 127.6996\n",
      "[Epoch 58/201]: loss = 128.4161\n",
      "[Epoch 59/201]: loss = 118.4825\n",
      "[Epoch 60/201]: loss = 121.2052\n",
      "[Epoch 61/201]: loss = 118.2157\n",
      "[Epoch 62/201]: loss = 125.7046\n",
      "[Epoch 63/201]: loss = 110.2707\n",
      "[Epoch 64/201]: loss = 99.8064\n",
      "[Epoch 65/201]: loss = 105.5950\n",
      "[Epoch 66/201]: loss = 98.1833\n",
      "[Epoch 67/201]: loss = 98.2129\n",
      "[Epoch 68/201]: loss = 88.3838\n",
      "[Epoch 69/201]: loss = 92.7533\n",
      "[Epoch 70/201]: loss = 95.4788\n",
      "[Epoch 71/201]: loss = 82.6422\n",
      "[Epoch 72/201]: loss = 79.7670\n",
      "[Epoch 73/201]: loss = 82.6046\n",
      "[Epoch 74/201]: loss = 75.9644\n",
      "[Epoch 75/201]: loss = 72.0974\n",
      "[Epoch 76/201]: loss = 72.4341\n",
      "[Epoch 77/201]: loss = 70.0094\n",
      "[Epoch 78/201]: loss = 72.0615\n",
      "[Epoch 79/201]: loss = 66.7886\n",
      "[Epoch 80/201]: loss = 65.3309\n",
      "[Epoch 81/201]: loss = 64.3908\n",
      "[Epoch 82/201]: loss = 63.8955\n",
      "[Epoch 83/201]: loss = 61.4929\n",
      "[Epoch 84/201]: loss = 60.3676\n",
      "[Epoch 85/201]: loss = 58.3153\n",
      "[Epoch 86/201]: loss = 57.5214\n",
      "[Epoch 87/201]: loss = 57.4891\n",
      "[Epoch 88/201]: loss = 54.4848\n",
      "[Epoch 89/201]: loss = 53.8881\n",
      "[Epoch 90/201]: loss = 51.0317\n",
      "[Epoch 91/201]: loss = 51.4484\n",
      "[Epoch 92/201]: loss = 49.6272\n",
      "[Epoch 93/201]: loss = 50.4466\n",
      "[Epoch 94/201]: loss = 49.0922\n",
      "[Epoch 95/201]: loss = 46.3411\n",
      "[Epoch 96/201]: loss = 46.5345\n",
      "[Epoch 97/201]: loss = 48.6434\n",
      "[Epoch 98/201]: loss = 45.7275\n",
      "[Epoch 99/201]: loss = 45.8672\n",
      "[Epoch 100/201]: loss = 46.4443\n",
      "[Epoch 101/201]: loss = 44.2685\n",
      "[Epoch 102/201]: loss = 45.6274\n",
      "[Epoch 103/201]: loss = 44.5336\n",
      "[Epoch 104/201]: loss = 42.6459\n",
      "[Epoch 105/201]: loss = 43.6997\n",
      "[Epoch 106/201]: loss = 42.7097\n",
      "[Epoch 107/201]: loss = 42.9618\n",
      "[Epoch 108/201]: loss = 41.9316\n",
      "[Epoch 109/201]: loss = 42.4401\n",
      "[Epoch 110/201]: loss = 42.0999\n",
      "[Epoch 111/201]: loss = 41.7710\n",
      "[Epoch 112/201]: loss = 40.1991\n",
      "[Epoch 113/201]: loss = 40.1735\n",
      "[Epoch 114/201]: loss = 41.2282\n",
      "[Epoch 115/201]: loss = 40.4257\n",
      "[Epoch 116/201]: loss = 39.9735\n",
      "[Epoch 117/201]: loss = 39.1846\n",
      "[Epoch 118/201]: loss = 39.7741\n",
      "[Epoch 119/201]: loss = 39.1581\n",
      "[Epoch 120/201]: loss = 39.2126\n",
      "[Epoch 121/201]: loss = 38.3683\n",
      "[Epoch 122/201]: loss = 37.8399\n",
      "[Epoch 123/201]: loss = 38.6921\n",
      "[Epoch 124/201]: loss = 38.1436\n",
      "[Epoch 125/201]: loss = 38.1663\n",
      "[Epoch 126/201]: loss = 36.7454\n",
      "[Epoch 127/201]: loss = 38.1713\n",
      "[Epoch 128/201]: loss = 36.4840\n",
      "[Epoch 129/201]: loss = 36.7865\n",
      "[Epoch 130/201]: loss = 36.5610\n",
      "[Epoch 131/201]: loss = 35.6314\n",
      "[Epoch 132/201]: loss = 36.6756\n",
      "[Epoch 133/201]: loss = 35.8726\n",
      "[Epoch 134/201]: loss = 34.3249\n",
      "[Epoch 135/201]: loss = 34.0032\n",
      "[Epoch 136/201]: loss = 33.7960\n",
      "[Epoch 137/201]: loss = 33.4084\n",
      "[Epoch 138/201]: loss = 32.8863\n",
      "[Epoch 139/201]: loss = 33.9440\n",
      "[Epoch 140/201]: loss = 32.7769\n",
      "[Epoch 141/201]: loss = 33.7171\n",
      "[Epoch 142/201]: loss = 32.1748\n",
      "[Epoch 143/201]: loss = 32.6506\n",
      "[Epoch 144/201]: loss = 34.0120\n",
      "[Epoch 145/201]: loss = 32.9045\n",
      "[Epoch 146/201]: loss = 32.4414\n",
      "[Epoch 147/201]: loss = 32.8504\n",
      "[Epoch 148/201]: loss = 32.7758\n",
      "[Epoch 149/201]: loss = 31.5177\n",
      "[Epoch 150/201]: loss = 32.0336\n",
      "[Epoch 151/201]: loss = 32.4016\n",
      "[Epoch 152/201]: loss = 31.8963\n",
      "[Epoch 153/201]: loss = 30.8664\n",
      "[Epoch 154/201]: loss = 31.3713\n",
      "[Epoch 155/201]: loss = 30.7549\n",
      "[Epoch 156/201]: loss = 31.0158\n",
      "[Epoch 157/201]: loss = 30.1460\n",
      "[Epoch 158/201]: loss = 31.4484\n",
      "[Epoch 159/201]: loss = 31.8824\n",
      "[Epoch 160/201]: loss = 31.7320\n",
      "[Epoch 161/201]: loss = 29.8438\n",
      "[Epoch 162/201]: loss = 31.9817\n",
      "[Epoch 163/201]: loss = 30.5321\n",
      "[Epoch 164/201]: loss = 30.2854\n",
      "[Epoch 165/201]: loss = 29.9053\n",
      "[Epoch 166/201]: loss = 29.4471\n",
      "[Epoch 167/201]: loss = 30.0482\n",
      "[Epoch 168/201]: loss = 29.7766\n",
      "[Epoch 169/201]: loss = 29.5178\n",
      "[Epoch 170/201]: loss = 29.3703\n",
      "[Epoch 171/201]: loss = 29.7589\n",
      "[Epoch 172/201]: loss = 28.5791\n",
      "[Epoch 173/201]: loss = 30.0668\n",
      "[Epoch 174/201]: loss = 29.3441\n",
      "[Epoch 175/201]: loss = 28.9130\n",
      "[Epoch 176/201]: loss = 29.8991\n",
      "[Epoch 177/201]: loss = 29.1493\n",
      "[Epoch 178/201]: loss = 30.2216\n",
      "[Epoch 179/201]: loss = 30.1336\n",
      "[Epoch 180/201]: loss = 27.9193\n",
      "[Epoch 181/201]: loss = 30.1276\n",
      "[Epoch 182/201]: loss = 28.8542\n",
      "[Epoch 183/201]: loss = 31.0944\n",
      "[Epoch 184/201]: loss = 28.8309\n",
      "[Epoch 185/201]: loss = 29.2731\n",
      "[Epoch 186/201]: loss = 28.5985\n",
      "[Epoch 187/201]: loss = 28.0406\n",
      "[Epoch 188/201]: loss = 29.1274\n",
      "[Epoch 189/201]: loss = 27.8451\n",
      "[Epoch 190/201]: loss = 27.9250\n",
      "[Epoch 191/201]: loss = 28.1963\n",
      "[Epoch 192/201]: loss = 28.2793\n",
      "[Epoch 193/201]: loss = 27.6953\n",
      "[Epoch 194/201]: loss = 28.8896\n",
      "[Epoch 195/201]: loss = 28.4549\n",
      "[Epoch 196/201]: loss = 27.6297\n",
      "[Epoch 197/201]: loss = 28.1958\n",
      "[Epoch 198/201]: loss = 28.4880\n",
      "[Epoch 199/201]: loss = 28.2603\n",
      "[Epoch 200/201]: loss = 26.8979\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in tqdm(range(1, NUM_EPOCHS+1)):\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(X, y, edge_idx, edge_wt, sample=True)\n",
    "    loss = loss_mse(y, y_hat)\n",
    "    print(f\"[Epoch {epoch}/{NUM_EPOCHS}]: loss = {loss.item():.4f}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'trial_0_single_batch.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
